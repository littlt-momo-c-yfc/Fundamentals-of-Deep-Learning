{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1423b72",
   "metadata": {},
   "source": [
    "# Resnet18 应用于 CIFAR10 分类\n",
    "\n",
    "终于可以说一下Resnet分类网络了，它差不多是当前应用最为广泛的CNN特征提取网络。细节大家可以参考这篇论文：\n",
    "\n",
    "Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Deep Residual Learning for Image Recognition, CVPR 2016.\n",
    "\n",
    "我们的一般印象当中，CNN越深就越具有更强的表达能力。因此，CNN分类网络自Alexnet的7层发展到了VGG的19层，后来有了Googlenet的22层。可后来我们发现深度CNN网络达到一定深度后再一味地增加层数并不能带来进一步地分类性能提高，反而会招致网络收敛变得更慢，分类准确率也变得更差。\n",
    "\n",
    "## 1. BasicBlock\n",
    "\n",
    "何恺明想到了常规视觉领域常用的residual representation的概念，并进一步将它应用在了CNN模型的构建当中，于是就有了基本的residual learning的 BasicBlock。\n",
    "\n",
    "\n",
    "BasicBlock 通过Identity mapping的引入在输入、输出之间建立了一条直接的关联通道，从而使得强大的有参层集中精力学习输入、输出之间的残差。简来说，残差更小，学习起来更容易，也收敛更快。\n",
    "\n",
    "下面我们看一下 BasicBlock 的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e11e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b796a",
   "metadata": {},
   "source": [
    "代码比较简单，非常容易看懂，需要注意的是，stride 步长可能是1，也可能是2。如果步长是2的话，两个 feature map 尺寸不一样，就不能做加法了；同样，如果两个 feature map 的通道数不一样，也无法做加法。所有，有一个判断专门处理这个。\n",
    "\n",
    "## 2. Bottleneck Block\n",
    "\n",
    "为了实际计算的考虑，作者提出了一种bottleneck的结构块来代替上面的 Residual block，它像Inception网络那样通过使用1x1 conv来巧妙地缩减或扩张feature map维度从而使得 3x3 的卷积核数目不受外界即上一层输入的影响，自然它的输出也不会影响到下一层，具体图示如下：\n",
    "\n",
    "\n",
    "实现的代码如下所示：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c8f2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3209866",
   "metadata": {},
   "source": [
    "## 3. 创建dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ec46bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 使用GPU训练，可以在菜单 \"代码执行工具\" -> \"更改运行时类型\" 里进行设置\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,  download=True, transform=transform_train)\n",
    "testset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de24084",
   "metadata": {},
   "source": [
    "## 4. 创建 ResNet18 网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea9f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.num_classes = 10\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(BasicBlock, 64,  2, stride=1)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n",
    "        self.linear = nn.Linear(512, self.num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))  \n",
    "        # 64 * 32 * 32\n",
    "        out = self.layer1(out)\n",
    "        # 64 * 32 * 32\n",
    "        out = self.layer2(out)\n",
    "        # 128 * 16 * 16    \n",
    "        out = self.layer3(out)\n",
    "        # 256 * 8 * 8   \n",
    "        out = self.layer4(out)\n",
    "        # 512 * 4 * 4        \n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        # 512 * 1 * 1\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59da773d",
   "metadata": {},
   "source": [
    "实例化网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed78412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络放到GPU上\n",
    "net = ResNet18().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea843b",
   "metadata": {},
   "source": [
    "## 5. 模型训练：\n",
    "\n",
    "训练代码和之前的完全一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4621c45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Minibatch:     1 loss: 2.384\n",
      "Epoch: 1 Minibatch:   101 loss: 1.613\n",
      "Epoch: 1 Minibatch:   201 loss: 1.326\n",
      "Epoch: 1 Minibatch:   301 loss: 1.268\n",
      "Epoch: 2 Minibatch:     1 loss: 1.031\n",
      "Epoch: 2 Minibatch:   101 loss: 1.089\n",
      "Epoch: 2 Minibatch:   201 loss: 1.009\n",
      "Epoch: 2 Minibatch:   301 loss: 0.759\n",
      "Epoch: 3 Minibatch:     1 loss: 0.796\n",
      "Epoch: 3 Minibatch:   101 loss: 0.918\n",
      "Epoch: 3 Minibatch:   201 loss: 1.030\n",
      "Epoch: 3 Minibatch:   301 loss: 0.682\n",
      "Epoch: 4 Minibatch:     1 loss: 0.602\n",
      "Epoch: 4 Minibatch:   101 loss: 0.847\n",
      "Epoch: 4 Minibatch:   201 loss: 0.736\n",
      "Epoch: 4 Minibatch:   301 loss: 0.710\n",
      "Epoch: 5 Minibatch:     1 loss: 0.502\n",
      "Epoch: 5 Minibatch:   101 loss: 0.570\n",
      "Epoch: 5 Minibatch:   201 loss: 0.600\n",
      "Epoch: 5 Minibatch:   301 loss: 0.580\n",
      "Epoch: 6 Minibatch:     1 loss: 0.461\n",
      "Epoch: 6 Minibatch:   101 loss: 0.485\n",
      "Epoch: 6 Minibatch:   201 loss: 0.503\n",
      "Epoch: 6 Minibatch:   301 loss: 0.592\n",
      "Epoch: 7 Minibatch:     1 loss: 0.366\n",
      "Epoch: 7 Minibatch:   101 loss: 0.437\n",
      "Epoch: 7 Minibatch:   201 loss: 0.427\n",
      "Epoch: 7 Minibatch:   301 loss: 0.481\n",
      "Epoch: 8 Minibatch:     1 loss: 0.453\n",
      "Epoch: 8 Minibatch:   101 loss: 0.331\n",
      "Epoch: 8 Minibatch:   201 loss: 0.429\n",
      "Epoch: 8 Minibatch:   301 loss: 0.380\n",
      "Epoch: 9 Minibatch:     1 loss: 0.397\n",
      "Epoch: 9 Minibatch:   101 loss: 0.373\n",
      "Epoch: 9 Minibatch:   201 loss: 0.269\n",
      "Epoch: 9 Minibatch:   301 loss: 0.378\n",
      "Epoch: 10 Minibatch:     1 loss: 0.258\n",
      "Epoch: 10 Minibatch:   101 loss: 0.333\n",
      "Epoch: 10 Minibatch:   201 loss: 0.294\n",
      "Epoch: 10 Minibatch:   301 loss: 0.348\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # 重复多轮训练\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 优化器梯度归零\n",
    "        optimizer.zero_grad()\n",
    "        # 正向传播 +　反向传播 + 优化 \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 输出统计信息\n",
    "        if i % 100 == 0:   \n",
    "            print('Epoch: %d Minibatch: %5d loss: %.3f' %(epoch + 1, i + 1, loss.item()))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad481bc0",
   "metadata": {},
   "source": [
    "## 6. 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e4edc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 85.33 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf5a447",
   "metadata": {},
   "source": [
    "一个神奇的时刻，准确率在 InceptionV3 的基础上又提高了 0.56 个百分点 ~\n",
    "\n",
    "其实我是故意的，提升是非常容易的，多跑几个 epoch 就行了。\n",
    "\n",
    "现在还留有余地  因为有了残差学习，我们非常容易的就能够把网络加深，到50层，100层 \n",
    "\n",
    "精力有限，这里我就不再跑 ResNet50 了，但代码提供在下面，感兴趣的同学可以自己跑一跑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(Bottleneck, 64,  3, stride=1)\n",
    "        self.layer2 = self._make_layer(Bottleneck, 128, 4, stride=2)\n",
    "        self.layer3 = self._make_layer(Bottleneck, 256, 6, stride=2)\n",
    "        self.layer4 = self._make_layer(Bottleneck, 512, 3, stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
